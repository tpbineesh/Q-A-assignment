# -*- coding: utf-8 -*-
"""Final_For Modelling

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZnKxRFrgk18moW49saBBs9Xcek0wGIul
"""

#Week 2&3- Pre-processing and one model

# Import the libraries
import pandas as pd
import numpy as np
import seaborn as sns

# Import the dataset
dataset = pd.read_csv('/content/Project group 11.csv')
dataset

dataset.shape

dataset.info()

#Finding missing value

dataset.isna().sum()

"""There are no missing values"""

dataset.head(5)

"""The given data set has some irrelevant coloumns like StandardHours,Over18, employee count etc. We can drop these columns"""

#Dropping irrelevant values

dataset1=dataset.drop('StandardHours',axis=1)
dataset1

dataset2=dataset1.drop('Over18',axis=1)

dataset2.head()

dataset3=dataset2.drop('EmployeeCount',axis=1)

dataset3.head()

#Outlier detection

dataset3.dtypes

import matplotlib.pyplot as plt

plt.boxplot(dataset3['Age'])
plt.title('Age')

plt.boxplot(dataset3['DailyRate'])
plt.title('DailyRate')

plt.boxplot(dataset3['DistanceFromHome'])
plt.title('DistanceFromHome')

plt.boxplot(dataset3['Education'])
plt.title('Education')

plt.boxplot(dataset3['EmployeeNumber'])
plt.title('EmployeeNumber')

plt.boxplot(dataset3['EnvironmentSatisfaction'])
plt.title('EnvironmentSatisfaction')

plt.boxplot(dataset3['HourlyRate'])
plt.title('HourlyRate')

plt.boxplot(dataset3['JobInvolvement'])
plt.title('JobInvolvement')

plt.boxplot(dataset3['JobLevel'])
plt.title('JobLevel')

plt.boxplot(dataset3['MonthlyIncome'])
plt.title('MonthlyIncome')

plt.boxplot(dataset3['MonthlyRate'])
plt.title('MonthlyRate')

plt.boxplot(dataset3['JobSatisfaction'])
plt.title('JobSatisfaction')

plt.boxplot(dataset3['NumCompaniesWorked'])
plt.title('NumCompaniesWorked')

plt.boxplot(dataset3['PercentSalaryHike'])
plt.title('PercentSalaryHike')

plt.boxplot(dataset3['PerformanceRating'])
plt.title('PerformanceRating')

plt.boxplot(dataset3['RelationshipSatisfaction'])
plt.title('RelationshipSatisfaction')

plt.boxplot(dataset3['StockOptionLevel'])
plt.title('StockOptionLevel')

plt.boxplot(dataset3['TotalWorkingYears'])
plt.title('TotalWorkingYears')

plt.boxplot(dataset3['TrainingTimesLastYear'])
plt.title('TrainingTimesLastYear')

plt.boxplot(dataset3['WorkLifeBalance'])
plt.title('WorkLifeBalance ')

plt.boxplot(dataset3['YearsAtCompany'])
plt.title('YearsAtCompany')

plt.boxplot(dataset3['YearsInCurrentRole'])
plt.title('YearsInCurrentRole')

plt.boxplot(dataset3['YearsSinceLastPromotion'])
plt.title('YearsSinceLastPromotion')

plt.boxplot(dataset3['YearsWithCurrManager'])
plt.title('YearsWithCurrManager')

"""We found outliers in MonthlyIncome,StockOptionLevel,TotalWorkingYears,TrainingTimesLastYear,YearsAtCompany,YearsInCurrentRole,YearsSinceLastPromotion,YearsWithCurrManager etc"""

# Dealing with outliers

Q1=np.percentile(dataset3['MonthlyIncome'],25,interpolation='midpoint')
Q2=np.percentile(dataset3['MonthlyIncome'],50,interpolation='midpoint')
Q3=np.percentile(dataset3['MonthlyIncome'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

print(low_lim)
print(Up_lim)

dataset4=dataset3[(dataset3.MonthlyIncome>low_lim)&(dataset3.MonthlyIncome<Up_lim)]
dataset4

plt.boxplot(dataset4['MonthlyIncome'])
plt.title('MonthlyIncome')

Q1=np.percentile(dataset4['NumCompaniesWorked'],25,interpolation='midpoint')
Q2=np.percentile(dataset4['NumCompaniesWorked'],50,interpolation='midpoint')
Q3=np.percentile(dataset4['NumCompaniesWorked'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset5=dataset4[(dataset4.NumCompaniesWorked>low_lim)&(dataset4.NumCompaniesWorked<Up_lim)]
dataset5

dataset5.head()

plt.boxplot(dataset5['NumCompaniesWorked'])
plt.title('NumCompaniesWorked')

Q1=np.percentile(dataset5['StockOptionLevel'],25,interpolation='midpoint')
Q2=np.percentile(dataset5['StockOptionLevel'],50,interpolation='midpoint')
Q3=np.percentile(dataset5['StockOptionLevel'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset6=dataset5[(dataset5.StockOptionLevel>low_lim)&(dataset5.StockOptionLevel<Up_lim)]
dataset6

plt.boxplot(dataset6['StockOptionLevel'])
plt.title('StockOptionLevel')

Q1=np.percentile(dataset6['TotalWorkingYears'],25,interpolation='midpoint')
Q2=np.percentile(dataset6['TotalWorkingYears'],50,interpolation='midpoint')
Q3=np.percentile(dataset6['TotalWorkingYears'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset7=dataset6[(dataset6.TotalWorkingYears>low_lim)&(dataset6.TotalWorkingYears<Up_lim)]
dataset7

plt.boxplot(dataset7['TotalWorkingYears'])
plt.title('TotalWorkingYears')

Q1=np.percentile(dataset7['TrainingTimesLastYear'],25,interpolation='midpoint')
Q2=np.percentile(dataset7['TrainingTimesLastYear'],50,interpolation='midpoint')
Q3=np.percentile(dataset7['TrainingTimesLastYear'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset8=dataset7[(dataset7.TrainingTimesLastYear>low_lim)&(dataset7.TrainingTimesLastYear<Up_lim)]
dataset8

plt.boxplot(dataset8['TrainingTimesLastYear'])
plt.title('TrainingTimesLastYear')

Q1=np.percentile(dataset8['YearsAtCompany'],25,interpolation='midpoint')
Q2=np.percentile(dataset8['YearsAtCompany'],50,interpolation='midpoint')
Q3=np.percentile(dataset8['YearsAtCompany'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset9=dataset8[(dataset8.YearsAtCompany>low_lim)&(dataset8.YearsAtCompany<Up_lim)]
dataset9

plt.boxplot(dataset9['YearsAtCompany'])
plt.title('YearsAtCompany')

Q1=np.percentile(dataset9['YearsInCurrentRole'],25,interpolation='midpoint')
Q2=np.percentile(dataset9['YearsInCurrentRole'],50,interpolation='midpoint')
Q3=np.percentile(dataset9['YearsInCurrentRole'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset10=dataset9[(dataset9.YearsInCurrentRole>low_lim)&(dataset9.YearsInCurrentRole<Up_lim)]
dataset10

plt.boxplot(dataset10['YearsInCurrentRole'])
plt.title('YearsInCurrentRole')

Q1=np.percentile(dataset10['YearsSinceLastPromotion'],25,interpolation='midpoint')
Q2=np.percentile(dataset10['YearsSinceLastPromotion'],50,interpolation='midpoint')
Q3=np.percentile(dataset10['YearsSinceLastPromotion'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset11=dataset10[(dataset10.YearsSinceLastPromotion>low_lim)&(dataset10.YearsSinceLastPromotion<Up_lim)]
dataset11

plt.boxplot(dataset11['YearsSinceLastPromotion'])
plt.title('YearsSinceLastPromotion')

Q1=np.percentile(dataset11['YearsWithCurrManager'],25,interpolation='midpoint')
Q2=np.percentile(dataset11['YearsWithCurrManager'],50,interpolation='midpoint')
Q3=np.percentile(dataset11['YearsWithCurrManager'],75,interpolation='midpoint')

print(Q1)
print(Q2)
print(Q3)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
Up_lim=Q3+1.5*IQR

dataset12=dataset11[(dataset11.YearsWithCurrManager>low_lim)&(dataset11.YearsWithCurrManager<Up_lim)]
dataset12

plt.boxplot(dataset12['YearsWithCurrManager'])
plt.title('YearsWithCurrManager')

"""#Encoding"""

dataset12.dtypes

#Checking for unique values

for column in dataset12.columns:
  if dataset12[column].dtype==object:
    print(str(column)+':'+str(dataset12[column].unique()))
    print(dataset12[column].value_counts())
    print('-------------------------------')

"""We can proceed with encoding. We can perform label encoding to Attrition,Gender and overtime columns."""

from sklearn import preprocessing

label_encoder = preprocessing.LabelEncoder()

dataset12['Attrition']= label_encoder.fit_transform(dataset12['Attrition'])

dataset12

dataset12['Gender']= label_encoder.fit_transform(dataset12['Gender'])

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', -1)

dataset12.head()

dataset12['OverTime']= label_encoder.fit_transform(dataset12['OverTime'])

dataset12.head()

dataset12=pd.get_dummies(dataset12)
dataset12.head()

dataset13=dataset12.drop(dataset12.loc[:, 'MonthlyRate':'RelationshipSatisfaction'].columns, axis = 1)

dataset13.head()

dataset14=dataset13.drop(dataset12.loc[:, 'TotalWorkingYears':'MaritalStatus_Single'].columns, axis = 1)

dataset14.head()

dataset15=dataset14.drop(dataset12.loc[:, 'DailyRate':'EnvironmentSatisfaction'].columns, axis = 1)

dataset15.head()

dataset16=dataset15.drop(['HourlyRate','JobLevel'],axis=1)

dataset16.head()

dataset17=dataset16.drop(['Age'],axis=1)

dataset17.head()

y=dataset17['Attrition']
x=dataset17.drop(['Attrition'],axis=1)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.25)

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()
x_train=sc.fit_transform(x_train)
x_test=sc.transform(x_test)

# Use Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
forest=RandomForestClassifier(n_estimators=10, criterion='entropy',random_state=42)
forest.fit(x_train, y_train)

# Finding accuracy on trainng dataset
forest.score(x_train,y_train)

# Finding confusion matrix and accuracy score for test dataset
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report

cm=confusion_matrix(y_test,forest.predict(x_test))
cm

accuracy_score(y_test,forest.predict(x_test))

print(classification_report(y_test,forest.predict(x_test)))

dataset17.head()

"""#Logistic Regression"""

from sklearn.linear_model import LogisticRegression
logit_model=LogisticRegression()
logit_model.fit(x_train,y_train)
y_pred = logit_model.predict(x_test)

from sklearn.metrics import precision_score,recall_score,f1_score,classification_report

print("Accuracy is:",accuracy_score(y_test,y_pred))
print("Precision is:",precision_score(y_test,y_pred,average='micro'))
print("Recall is:",recall_score(y_test,y_pred,average='micro'))
print("f1_score is:",f1_score(y_test,y_pred,average='micro'))

print(classification_report(y_test,y_pred))

confusion_matrix(y_test,y_pred)

from sklearn.neighbors import KNeighborsClassifier
acc_values=[]
neighbors=np.arange(3,15)
for k in neighbors:
  classifier=KNeighborsClassifier(n_neighbors=k, metric='minkowski')
  classifier.fit(x_train,y_train)
  y_pred=classifier.predict(x_test)
  acc=accuracy_score(y_test,y_pred)
  acc_values.append(acc)

acc_values

plt.plot(neighbors,acc_values,'o-')
plt.xlabel('k value')
plt.ylabel('accuracy')

classifier=KNeighborsClassifier(n_neighbors=4, metric='minkowski')
classifier.fit(x_train,y_train)
y_pred=classifier.predict(x_test)

print("Accuracy is:",accuracy_score(y_test,y_pred))
print("Precision is:",precision_score(y_test,y_pred,average='micro'))
print("Recall is:",recall_score(y_test,y_pred,average='micro'))
print("f1_score is:",f1_score(y_test,y_pred,average='micro'))

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

"""#Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier()

tree.fit(x_train,y_train)

predict_tree=tree.predict(x_test)

print(accuracy_score(y_test,predict_tree))

from sklearn.metrics import classification_report

print(classification_report(y_test,predict_tree))

"""#SVM"""

from sklearn.svm import SVC
svc = SVC()

svc.fit(x_train,y_train)

predict_svc=svc.predict(x_test)

print(accuracy_score(y_test,predict_svc))

print(classification_report(y_test,predict_svc))

"""From the model evaluated, the best one is logistic regression"""

